{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "def cleanup():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "preds = ['You are good at it!', 'It is a beautiful day!', 'Another sentence']\n",
    "inputs = ['Fuck you peasant', 'Today is a beautiful day!', 'Some other sentence']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, \\\n",
    "    RobertaTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import tqdm\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "def classify_preds(preds, batch_size = 1):\n",
    "    print('Calculating style of predictions')\n",
    "    results = []\n",
    "\n",
    "    model_name = 'SkolkovoInstitute/roberta_toxicity_classifier'\n",
    "\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "    model = RobertaForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    for i in tqdm.tqdm(range(0, len(preds), batch_size)):\n",
    "        batch = tokenizer(preds[i:i + batch_size], return_tensors='pt', padding=True)\n",
    "        with torch.inference_mode():\n",
    "            logits = model(**batch).logits\n",
    "            result = torch.softmax(logits, -1)[:, 1].cpu().numpy()\n",
    "        results.extend([1 - item for item in result])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating style of predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 3/3 [00:00<00:00, 25.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999573198510916\n"
     ]
    }
   ],
   "source": [
    "accuracy_by_sent = classify_preds(preds)\n",
    "accuracy = sum(accuracy_by_sent)/len(preds)\n",
    "print(accuracy)\n",
    "cleanup()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "# Function to calculate cosine similarity between two lists of sentence embeddings\n",
    "def calculate_similarity(input_sentences, pred_sentences, model, tokenizer):\n",
    "    # Tokenize input sentences\n",
    "    input_encoded = tokenizer(input_sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "    pred_encoded = tokenizer(pred_sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings for input and prediction sentences\n",
    "    with torch.no_grad():\n",
    "        input_model_output = model(**input_encoded)\n",
    "        pred_model_output = model(**pred_encoded)\n",
    "\n",
    "    # Perform pooling for input and prediction sentences\n",
    "    input_embeddings = mean_pooling(input_model_output, input_encoded['attention_mask'])\n",
    "    pred_embeddings = mean_pooling(pred_model_output, pred_encoded['attention_mask'])\n",
    "\n",
    "    # Normalize embeddings\n",
    "    input_embeddings = F.normalize(input_embeddings, p=2, dim=1)\n",
    "    pred_embeddings = F.normalize(pred_embeddings, p=2, dim=1)\n",
    "\n",
    "    # Calculate cosine similarity between the corresponding pairs of embeddings\n",
    "    similarity_scores = []\n",
    "    for i in range(len(input_sentences)):\n",
    "        similarity = 1 - cosine(input_embeddings[i], pred_embeddings[i])\n",
    "        similarity_scores.append(similarity)\n",
    "\n",
    "    return similarity_scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5942550847927729\n"
     ]
    }
   ],
   "source": [
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Calculate cosine similarity between input and prediction sentences\n",
    "similarity_scores = calculate_similarity(inputs, preds, model, tokenizer)\n",
    "\n",
    "similarity = sum(similarity_scores) / len(similarity_scores)\n",
    "print(similarity)\n",
    "cleanup()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from tqdm.auto import trange\n",
    "\n",
    "def detokenize(x):\n",
    "    return x.replace(\" .\", \".\").replace(\" ,\", \",\").replace(\" !\", \"!\").replace(\" ?\", \"?\").replace(\" )\",\")\").replace(\"( \", \"(\")\n",
    "\n",
    "def do_cola_eval_transformers(preds):\n",
    "    print('Calculating CoLA acceptability stats')\n",
    "    path = \"cointegrated/roberta-large-cola-krishna2020\"\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "\n",
    "    results = []\n",
    "    bs = 1\n",
    "    for i in trange(0, len(preds), bs):\n",
    "        batch = [detokenize(t) for t in preds[i: i + bs]]\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors='pt').to(model.device)\n",
    "        with torch.no_grad():\n",
    "            out = torch.softmax(model(**inputs).logits, -1)[:, 0].cpu().numpy()\n",
    "            results.append(out)\n",
    "    return np.concatenate(results)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CoLA acceptability stats\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a15b0bd407834d1990d9395bc236db86"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8401714563369751\n"
     ]
    }
   ],
   "source": [
    "fluency = sum(do_cola_eval_transformers(inputs)) / len(inputs)\n",
    "print(fluency)\n",
    "cleanup()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ACC | SIM | FL | J |\n",
      "\n",
      "|1.0000|0.5943|0.8402|0.4993|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# count metrics\n",
    "joint = accuracy * similarity * fluency\n",
    "\n",
    "print('| ACC | SIM | FL | J |\\n')\n",
    "print(f'|{accuracy:.4f}|{similarity:.4f}|{fluency:.4f}|{joint:.4f}|\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating style of predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 3/3 [00:00<00:00, 26.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999573198510916\n",
      "0.5942550847927729\n",
      "Calculating CoLA acceptability stats\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90ca31e8b38b4d9bb8c9861f0f44494e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8401714563369751\n",
      "| ACC | SIM | FL | J |\n",
      "\n",
      "|1.0000|0.5943|0.8402|0.4993|\n",
      "\n",
      "0.49925485084514026\n"
     ]
    }
   ],
   "source": [
    "from J_metric import J\n",
    "\n",
    "result = J(inputs, preds)  # Call the J function with appropriate arguments\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
