{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                          reference   \n",
      "0           0  If Alkar is flooding her with psychic waste, t...  \\\n",
      "1           1                          Now you're getting nasty.   \n",
      "2           2           Well, we could spare your life, for one.   \n",
      "3           3          Ah! Monkey, you've got to snap out of it.   \n",
      "4           4                   I've got orders to put her down.   \n",
      "\n",
      "                                         translation  similarity  lenght_diff   \n",
      "0  if Alkar floods her with her mental waste, it ...    0.785171     0.010309  \\\n",
      "1                        you're becoming disgusting.    0.749687     0.071429   \n",
      "2                      well, we can spare your life.    0.919051     0.268293   \n",
      "3                       monkey, you have to wake up.    0.664333     0.309524   \n",
      "4                         I have orders to kill her.    0.726639     0.181818   \n",
      "\n",
      "    ref_tox   trn_tox  \n",
      "0  0.014195  0.981983  \n",
      "1  0.065473  0.999039  \n",
      "2  0.213313  0.985068  \n",
      "3  0.053362  0.994215  \n",
      "4  0.009402  0.999348  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "# Define the URL of the zip file\n",
    "zip_file_url = 'https://github.com/skoltech-nlp/detox/releases/download/emnlp2021/filtered_paranmt.zip'\n",
    "\n",
    "# Send an HTTP GET request to download the zip file\n",
    "response = requests.get(zip_file_url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Read the zip file\n",
    "    with zipfile.ZipFile(BytesIO(response.content)) as zip_file:\n",
    "        # Assuming there's only one .tsv file in the zip, you can read it like this\n",
    "        tsv_file = zip_file.namelist()[0]\n",
    "        with zip_file.open(tsv_file) as tsv:\n",
    "            # Read the .tsv file into a DataFrame\n",
    "            train_text = pd.read_csv(tsv, sep='\\t')\n",
    "\n",
    "            # Display the head of the DataFrame\n",
    "            head = train_text.head()\n",
    "            print(head)\n",
    "else:\n",
    "    print(\"Failed to download the zip file.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0                                          reference   \n0           0  If Alkar is flooding her with psychic waste, t...  \\\n1           1                          Now you're getting nasty.   \n2           2           Well, we could spare your life, for one.   \n3           3          Ah! Monkey, you've got to snap out of it.   \n4           4                   I've got orders to put her down.   \n\n                                         translation  similarity  lenght_diff   \n0  if Alkar floods her with her mental waste, it ...    0.785171     0.010309  \\\n1                        you're becoming disgusting.    0.749687     0.071429   \n2                      well, we can spare your life.    0.919051     0.268293   \n3                       monkey, you have to wake up.    0.664333     0.309524   \n4                         I have orders to kill her.    0.726639     0.181818   \n\n    ref_tox   trn_tox  \n0  0.014195  0.981983  \n1  0.065473  0.999039  \n2  0.213313  0.985068  \n3  0.053362  0.994215  \n4  0.009402  0.999348  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>reference</th>\n      <th>translation</th>\n      <th>similarity</th>\n      <th>lenght_diff</th>\n      <th>ref_tox</th>\n      <th>trn_tox</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>If Alkar is flooding her with psychic waste, t...</td>\n      <td>if Alkar floods her with her mental waste, it ...</td>\n      <td>0.785171</td>\n      <td>0.010309</td>\n      <td>0.014195</td>\n      <td>0.981983</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Now you're getting nasty.</td>\n      <td>you're becoming disgusting.</td>\n      <td>0.749687</td>\n      <td>0.071429</td>\n      <td>0.065473</td>\n      <td>0.999039</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Well, we could spare your life, for one.</td>\n      <td>well, we can spare your life.</td>\n      <td>0.919051</td>\n      <td>0.268293</td>\n      <td>0.213313</td>\n      <td>0.985068</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Ah! Monkey, you've got to snap out of it.</td>\n      <td>monkey, you have to wake up.</td>\n      <td>0.664333</td>\n      <td>0.309524</td>\n      <td>0.053362</td>\n      <td>0.994215</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>I've got orders to put her down.</td>\n      <td>I have orders to kill her.</td>\n      <td>0.726639</td>\n      <td>0.181818</td>\n      <td>0.009402</td>\n      <td>0.999348</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train_text.reference\n",
    "\n",
    "y = train_text['ref_tox']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, shuffle=True, random_state=123)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import _stop_words\n",
    "import string\n",
    "\n",
    "stop_words = _stop_words.ENGLISH_STOP_WORDS\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text_without_punct = text.translate(translator)\n",
    "    return text_without_punct\n",
    "\n",
    "def cleaning(doc):\n",
    "    # Remove punctuation\n",
    "    doc = remove_punctuation(doc)\n",
    "\n",
    "    doc = ''.join([word for word in doc if not word.isdigit()])\n",
    "\n",
    "    # Remove stop_words\n",
    "    tokens = doc.split()\n",
    "    cleaned_tokens = [token for token in tokens if token not in stop_words]\n",
    "    cleaned_doc = ' '.join(cleaned_tokens)\n",
    "\n",
    "    return cleaned_doc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(max_features=5000, preprocessor=cleaning)\n",
    "X_train_bow = vect.fit_transform(X_train)\n",
    "X_val_bow = vect.fit_transform(X_val)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "   AIDS  AND  Aah  About  According  Actually  Adam  Admiral  Africa  African   \n0     0    0    0      0          0         0     0        0       0        0  \\\n1     0    0    0      0          0         0     0        0       0        0   \n2     0    0    0      0          0         0     0        0       0        0   \n3     0    0    0      0          0         0     0        0       0        0   \n4     0    0    0      0          0         0     0        0       0        0   \n\n   ...  young  younger  youre  youth  youve  zero  zombie  zombies  zone  zoo  \n0  ...      0        0      0      0      0     0       0        0     0    0  \n1  ...      0        0      0      0      0     0       0        0     0    0  \n2  ...      0        0      0      0      0     0       0        0     0    0  \n3  ...      0        0      0      0      0     0       0        0     0    0  \n4  ...      0        0      0      0      0     0       0        0     0    0  \n\n[5 rows x 5000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AIDS</th>\n      <th>AND</th>\n      <th>Aah</th>\n      <th>About</th>\n      <th>According</th>\n      <th>Actually</th>\n      <th>Adam</th>\n      <th>Admiral</th>\n      <th>Africa</th>\n      <th>African</th>\n      <th>...</th>\n      <th>young</th>\n      <th>younger</th>\n      <th>youre</th>\n      <th>youth</th>\n      <th>youve</th>\n      <th>zero</th>\n      <th>zombie</th>\n      <th>zombies</th>\n      <th>zone</th>\n      <th>zoo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 5000 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_bow.A[:5], columns=vect.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn import preprocessing\n",
    "lab = preprocessing.LabelEncoder()\n",
    "y_transformed = lab.fit_transform(y_train)\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_bow, y_transformed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "y_val_transformed = lab.fit_transform(y_val)\n",
    "y_pred = classifier.predict(X_val)\n",
    "accuracy = accuracy_score(y_val_transformed, y_pred)\n",
    "mse = mean_squared_error(y_val_transformed, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[57], line 20\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Create and train a Logistic Regression classifier\u001B[39;00m\n\u001B[1;32m     19\u001B[0m classifier \u001B[38;5;241m=\u001B[39m LogisticRegression()\n\u001B[0;32m---> 20\u001B[0m \u001B[43mclassifier\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# Make predictions on the test data\u001B[39;00m\n\u001B[1;32m     23\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m classifier\u001B[38;5;241m.\u001B[39mpredict(X_test)\n",
      "File \u001B[0;32m~/Downloads/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1204\u001B[0m, in \u001B[0;36mLogisticRegression.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m   1194\u001B[0m     _dtype \u001B[38;5;241m=\u001B[39m [np\u001B[38;5;241m.\u001B[39mfloat64, np\u001B[38;5;241m.\u001B[39mfloat32]\n\u001B[1;32m   1196\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(\n\u001B[1;32m   1197\u001B[0m     X,\n\u001B[1;32m   1198\u001B[0m     y,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1202\u001B[0m     accept_large_sparse\u001B[38;5;241m=\u001B[39msolver \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mliblinear\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msag\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msaga\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m   1203\u001B[0m )\n\u001B[0;32m-> 1204\u001B[0m \u001B[43mcheck_classification_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1205\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_ \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(y)\n\u001B[1;32m   1207\u001B[0m multi_class \u001B[38;5;241m=\u001B[39m _check_multi_class(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmulti_class, solver, \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_))\n",
      "File \u001B[0;32m~/Downloads/venv/lib/python3.11/site-packages/sklearn/utils/multiclass.py:218\u001B[0m, in \u001B[0;36mcheck_classification_targets\u001B[0;34m(y)\u001B[0m\n\u001B[1;32m    210\u001B[0m y_type \u001B[38;5;241m=\u001B[39m type_of_target(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    211\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\n\u001B[1;32m    212\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    213\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultilabel-sequences\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    217\u001B[0m ]:\n\u001B[0;32m--> 218\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown label type: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m y_type)\n",
      "\u001B[0;31mValueError\u001B[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "# Example data (replace with your data)\n",
    "X_train = [\"This is a toxic sentence.\", \"This is a non-toxic sentence.\", \"Another toxic example.\"]\n",
    "y_train = np.array([0.8, 0.1, 0.9])  # Toxicity labels between 0 and 1\n",
    "\n",
    "# Create a CountVectorizer to convert words to vectors\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_counts, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train a Logistic Regression classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier (you can choose a different metric)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Example: Predict toxicity of a new sentence\n",
    "new_sentence = [\"This is a neutral sentence.\"]\n",
    "new_sentence_counts = vectorizer.transform(new_sentence)\n",
    "toxicity_score = classifier.predict(new_sentence_counts)\n",
    "print(\"Toxicity Score:\", toxicity_score[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
